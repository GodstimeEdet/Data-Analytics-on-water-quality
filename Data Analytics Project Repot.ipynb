{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0353e7c0",
   "metadata": {},
   "source": [
    "\n",
    "### The report contains:\n",
    "\n",
    "•\tGive your project a context- Story telling.\n",
    "\n",
    "•\tA detailed description of the variables originally present in the dataset\n",
    "\n",
    "o\tHow many observations per variable?\n",
    "\n",
    "o\tHow many missing values? Express it in percentage of the total observations\n",
    "\n",
    "o\tWhat type of variable?\n",
    "\n",
    "o\tHow many duplicates are present?\n",
    "\n",
    "o\tWhat are the unique values present per variable?\n",
    "\n",
    "o\tWhat are the frequencies of each unique observation? (when applicable)\n",
    "\n",
    "o\tWhat are the statistical properties of each variable?\n",
    "\n",
    "•\tFormulate a problem statement about the dataset.\n",
    "\n",
    "o\tWhat do you intend to do with the dataset? \n",
    "\n",
    "o\tIs it a regression type of analysis?\n",
    "\n",
    "o\tIs it a classification type analysis?\n",
    "\n",
    "o\tBoth types can be applied to the same dataset\n",
    "\n",
    "•\tA detailed strategy of selecting the variables. \n",
    "\n",
    "o\tWhy did you keep some variables?\n",
    "\n",
    "o\tWhy did you eliminate some variables?\n",
    "\n",
    "o\tHow and why did you decide to fill the missing values in some variables?\n",
    "\n",
    "o\tHow and why did you decide to handle the duplicates?\n",
    "\n",
    "o\tHow and why did you decide to apply a certain approach to handle extreme values?\n",
    "\n",
    "•\tChoose at least five graphics to represent best your data and strategy.\n",
    "\n",
    "o\tEach graphic should have a title and comments attached to it.\n",
    "\n",
    "o\tGraphics can either show the relationship between variables or between many variables or the statistical properties of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b22ee",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Give your project a context- Story telling.\n",
    "\n",
    "### Solution\n",
    "\n",
    "### Background\n",
    "\n",
    "In the year 2023, a team of environmental scientists embarked on a mission to analyze water quality data collected from various monitoring stations across the States. The data spanned five years, from 2002 to 2016, and included measurements of key water quality parameters such as temperature, dissolved oxygen, pH, conductivity, biochemical oxygen demand, nitrate and nitrite nitrogen, fecal coliform bacteria, and total coliform bacteria.\n",
    "\n",
    "The scientists were particularly interested in understanding the spatial and temporal variations in water quality across different regions and station types. They hoped to identify potential pollution sources, assess the overall health of aquatic ecosystems, and ultimately inform strategies for water quality management and protection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510bd405",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    " A detailed description of the variables originally present in the dataset\n",
    "\n",
    "\n",
    "### Solution\n",
    "\n",
    "### Feature Explanation\n",
    "\n",
    "1. **STATION CODE**:\n",
    "   - This feature represents a unique identifier assigned to each monitoring station where water quality measurements are taken. Each code corresponds to a specific sampling point.\n",
    "\n",
    "2. **LOCATIONS**:\n",
    "   - This feature contains the names of the locations where water samples are collected for quality assessment. It provides information about the specific places where the water quality measurements are recorded.\n",
    "\n",
    "3. **STATE**:\n",
    "   - This feature denotes the state where the monitoring station is situated. It indicates the geographical division or state within the country.\n",
    "\n",
    "4. **Temp**:\n",
    "   - This feature represents the water temperature measured at the sampling point. It indicates the degree of hotness or coldness of the water at the time of measurement.\n",
    "\n",
    "5. **D.O. (mg/l)** (Dissolved Oxygen):\n",
    "   - This feature represents the concentration of dissolved oxygen in the water, typically measured in milligrams per liter (mg/l). Dissolved oxygen is crucial for aquatic organisms and serves as an indicator of water quality.\n",
    "\n",
    "6. **PH**:\n",
    "   - pH is a measure of the acidity or alkalinity of the water. It indicates the hydrogen ion concentration and is measured on a scale of 0 to 14. A pH of 7 is considered neutral, while values below 7 are acidic and above 7 are alkaline.\n",
    "\n",
    "7. **CONDUCTIVITY (µmhos/cm)**:\n",
    "   - Conductivity is a measure of water's ability to conduct an electrical current. It is influenced by the presence of dissolved solids and ions. Conductivity is measured in microsiemens per centimeter (µS/cm) or micromhos per centimeter (µmhos/cm).\n",
    "\n",
    "8. **B.O.D. (mg/l)** (Biochemical Oxygen Demand):\n",
    "   - B.O.D. represents Biochemical Oxygen Demand, which measures the amount of dissolved oxygen required by microorganisms to break down organic matter in water. It is measured in milligrams per liter (mg/l).\n",
    "\n",
    "9. **NITRATENAN N+ NITRITENANN (mg/l)**:\n",
    "   - This feature may represent the combined concentration of nitrate and nitrite in water, measured in milligrams per liter (mg/l). Nitrate and nitrite are forms of nitrogen compounds and can be indicators of water pollution.\n",
    "\n",
    "10. **FECAL COLIFORM (MPN/100ml)**:\n",
    "    - Fecal coliform is a type of bacteria found in the feces of warm-blooded animals. Its presence in water indicates contamination by fecal matter. The concentration is typically measured in Most Probable Number per 100 milliliters (MPN/100ml).\n",
    "\n",
    "11. **TOTAL COLIFORM (MPN/100ml)Mean**:\n",
    "    - Total coliform represents a group of bacteria, including fecal coliform, found in the environment. It's an indicator of overall water quality. The concentration is measured in Most Probable Number per 100 milliliters (MPN/100ml).\n",
    "\n",
    "12. **year**:\n",
    "    - This feature denotes the year in which the water quality measurements were recorded. It indicates the temporal aspect or the year of the observation for the corresponding water quality data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5280f",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "How many observations per variable?\n",
    "\n",
    "### Solution\n",
    "\n",
    "We have a total of 1991 observations per variables with 12 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa2ce0b",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "How many missing values? Express it in percentage of the total observations\n",
    "\n",
    "### Solution\n",
    "\n",
    "We had about 11 features with missing values, The above shows the percentage representative of each features making state the highest with over 38.221999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97270735",
   "metadata": {},
   "source": [
    "### task 5\n",
    "\n",
    "What type of variable ?\n",
    "\n",
    "\n",
    "### Solution\n",
    "\n",
    "The following are type of variables with missing values values\n",
    "\n",
    "**STATE**                \n",
    "**Fec_col**           \n",
    "**NI**                     \n",
    "**LOCATIONS**      \n",
    "**Tot_col**           \n",
    "**STATION CODE**  \n",
    "**Temp**                 \n",
    "**BOD**                   \n",
    "**DO**                     \n",
    "**Conductivity**  \n",
    "**PH** \n",
    "\n",
    "Excluding\n",
    "\n",
    "**year**   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaebef3",
   "metadata": {},
   "source": [
    "### Task  6\n",
    "\n",
    "How many duplicates are present?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f35b1",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8645e557",
   "metadata": {},
   "source": [
    "Duplicate Rows:\n",
    "STATION CODE    0.0\n",
    "LOCATIONS       0.0\n",
    "STATE           0.0\n",
    "Temp            0.0\n",
    "DO              0.0\n",
    "PH              0.0\n",
    "Conductivity    0.0\n",
    "BOD             0.0\n",
    "NI              0.0\n",
    "Fec_col         0.0\n",
    "Tot_col         0.0\n",
    "year            0.0\n",
    "dtype: float64\n",
    "Empty DataFrame\n",
    "Columns: [STATION CODE, LOCATIONS, STATE, Temp, DO, PH, Conductivity, BOD, NI, Fec_col, Tot_col, year]\n",
    "Index: []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0da89",
   "metadata": {},
   "source": [
    "The output shows that there is absence of duplicate rows within the dataset containing water quality information across various parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7548e43",
   "metadata": {},
   "source": [
    "### task  7\n",
    "\n",
    " What are the unique values present per variable?\n",
    "    \n",
    "    \n",
    "### Solution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b69c5411",
   "metadata": {},
   "source": [
    "STATION CODE     321\n",
    "LOCATIONS        691\n",
    "STATE             24\n",
    "Temp             177\n",
    "DO               165\n",
    "PH               265\n",
    "Conductivity    1004\n",
    "BOD              407\n",
    "NI               506\n",
    "Fec_col          868\n",
    "Tot_col         1093\n",
    "year              12\n",
    "dtype: int64\n",
    "\n",
    "They above result display the unique values per variable in the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d82d107",
   "metadata": {},
   "source": [
    "### task  8\n",
    "What are the frequencies of each unique observation? (when applicable)\n",
    "\n",
    "### Solution\n",
    "\n",
    "The frequencies of a unique observation can only be applicable when variable has a categorical data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4439c",
   "metadata": {},
   "source": [
    "### task  9\n",
    "What are the statistical properties of each variable?\n",
    "\n",
    "### Solution\n",
    "\n",
    "![Image Description](stats.jpg)\n",
    "\n",
    "\n",
    "There are lots of high variance in the dataset that needs to be normalise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a34bd2f",
   "metadata": {},
   "source": [
    "### Task  10\n",
    "\n",
    "• Formulate a problem statement about the dataset.\n",
    "\n",
    "\n",
    "## Problem Statement:\n",
    "\n",
    "Understanding the Temporal and Geographical Variations in Water Quality Parameters and Evaluating Water Pollution Contributing Factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b886740",
   "metadata": {},
   "source": [
    "### task  11\n",
    "\n",
    "o What do you intend to do with the dataset? \n",
    "\n",
    "### Solution\n",
    "\n",
    "To carry out a prediction to know the water quality index for each observations when introduce to new data records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8a5f1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### task  12\n",
    "\n",
    "o Is it a regression type of analysis?\n",
    "\n",
    "### Solution\n",
    "\n",
    "After i introduce feature engineering to calculate the water quality index, this features tens to be my target variable for each observation.\n",
    "also the feature is a continuous numerical datapoint.\n",
    "in conclusion its a regression type of analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f10b091",
   "metadata": {},
   "source": [
    "### task  13\n",
    "\n",
    "Is it a classification type analysis?\n",
    "\n",
    "### Solution\n",
    "\n",
    "No. its not a classification type analysis, as it doesn't require a binary or multiclass type of analysis or prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c655d85",
   "metadata": {},
   "source": [
    "### task  14\n",
    "\n",
    "Both types can be applied to the same dataset?\n",
    "\n",
    "### Solution\n",
    "\n",
    "No. we can only apply regression type of analysis to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019075f2",
   "metadata": {},
   "source": [
    "### task  15\n",
    "\n",
    " A detailed strategy of selecting the variables. \n",
    "    \n",
    "### Solution\n",
    "\n",
    "![Image Description](heat.png)\n",
    "\n",
    "\n",
    "I use Heat map to visually representing the relationships and correlations between features in a dataset to aid in the selection of relevant variables.\n",
    "\n",
    "\n",
    "Using a heatmap in feature selection involves visually representing the relationships and correlations between features in a dataset to aid in the selection of relevant variables. Here's a summary of the process:\n",
    "\n",
    "**Correlation Visualization:**\n",
    "   - **Heatmap Representation:** Utilize a heatmap, often a colored matrix, to display correlation coefficients between different features in a dataset.\n",
    "   - **Color Gradients:** Assign color gradients to represent the strength and direction of correlations (positive or negative) between features.\n",
    "\n",
    "**Identifying Correlated Features:**\n",
    "   - **Visual Inspection:** Analyze the heatmap to identify clusters or patterns of high correlation between features.\n",
    "   - **Threshold Selection:** Set a correlation threshold to identify features that exhibit significant correlations with one another.\n",
    "\n",
    "**Feature Selection Criteria:**\n",
    "   - **Highly Correlated Features:** Consider removing one from a pair of highly correlated features to mitigate multicollinearity and reduce redundancy.\n",
    "   - **Relevant Features:** Prioritize features that show strong correlations with the target variable or with other key variables of interest.\n",
    "\n",
    "**Considerations and Interpretation:**\n",
    "   - **Domain Knowledge:** Complement heatmap analysis with domain-specific understanding to interpret and select features effectively.\n",
    "   - **Iterative Process:** Feature selection using a heatmap might involve multiple iterations to refine choices and account for changing analytical objectives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b895e",
   "metadata": {},
   "source": [
    "### task  16\n",
    "\n",
    "Why did you keep some variables?\n",
    "\n",
    "### Solution\n",
    "\n",
    "When we use heatmap for feature selection, the decision to keep certain variables is based on several factors related to their relevance, significance, and relationships with other variables in the dataset. Here's why some variables was being kept in the dataset:\n",
    "\n",
    "**High Correlation with Target Variable:**\n",
    "   - Variable like PH that exhibit strong correlations with the target variable or outcome of interest is being retained. These feature have a direct influence on predicting the target and is crucial for model performance.\n",
    "\n",
    "**Independently Informative Features:**\n",
    "   -  variables 'Temp', 'D.O. (mg/l)', 'PH',\n",
    "       'CONDUCTIVITY (µmhos/cm)', 'B.O.D. (mg/l)',\n",
    "       'NITRATENAN N+ NITRITENANN (mg/l)', 'FECAL COLIFORM (MPN/100ml)',\n",
    "       'TOTAL COLIFORM (MPN/100ml)Mean', 'year' does not exhibit high correlations with other variables but are independently informative for the analysis or predictive modeling. They provide unique information not captured by other features.\n",
    "\n",
    "**Multicollinearity Mitigation:**\n",
    "   - In cases of multicollinearity (high correlations between multiple features), keeping a subset of highly correlated features while removing others helps mitigate redundancy and multicollinearity issues. These retained variables might represent essential aspects of the data.\n",
    "\n",
    "**Strategic Model Complexity:**\n",
    "   - Keeping a subset of variables helps in controlling model complexity. Removing redundant or less informative features streamlines the model and prevents overfitting, leading to a more interpretable and robust model.\n",
    "\n",
    "\n",
    "In essence, the decision to keep certain variables while using a heatmap for feature selection involves a balance between their individual importance, relationships with other variables, domain relevance, and their contribution to achieving the desired analysis or modeling goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90189048",
   "metadata": {},
   "source": [
    "### task  17\n",
    "\n",
    "Why did you eliminate some variables?\n",
    "\n",
    "### Solution\n",
    "\n",
    "In the context of using a heatmap for feature selection, elimination of certain variables is necessary to enhance model performance, reduce complexity, and improve the interpretability of the analysis. \n",
    "\n",
    "Though, in the given dataset, there is no feature that shows less importance to the target variables.\n",
    "\n",
    "This are some reasons why some variables might be eliminated in other datasets.:\n",
    "\n",
    "1**High Multicollinearity:**\n",
    "   - When variables are highly correlated with each other, retaining all of them can introduce multicollinearity issues. Removing one of the highly correlated variables helps mitigate redundancy and stabilizes model estimation.\n",
    "\n",
    "**Low Correlation with Target Variable:**\n",
    "   - Variables that exhibit weak correlations with the target variable or outcome might not contribute significantly to predicting the target. Eliminating such variables can streamline the model and improve predictive accuracy.\n",
    "\n",
    "**Redundancy and Overfitting Prevention:**\n",
    "   - Redundant or unnecessary variables add complexity to the model without providing substantial information gain. Removing such variables helps prevent overfitting and enhances model generalization to new data.\n",
    "\n",
    "**Noise Reduction:**\n",
    "   - Variables with random or insignificant relationships with other features or the target variable add noise to the model. Eliminating noisy variables improves the signal-to-noise ratio and model robustness.\n",
    "\n",
    "**Dimensionality Reduction:**\n",
    "   - High-dimensional datasets with excessive variables can lead to the curse of dimensionality, making analysis and model training computationally intensive and prone to overfitting. Eliminating irrelevant variables reduces dimensionality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3d03f",
   "metadata": {},
   "source": [
    "### task  18\n",
    "\n",
    "How and why did you decide to fill the missing values in some variables?\n",
    "    \n",
    "### Solution\n",
    "\n",
    "**Why Fill Missing Values:**\n",
    "    \n",
    "    Filling missing values helps maintain the integrity of the dataset, preventing the loss of information that might be valuable for analysis.\n",
    "    \n",
    "    Many machine learning algorithms cannot handle missing values. Imputation allows for the use of these algorithms without discarding valuable data.\n",
    "    \n",
    "    Complete datasets contribute to a larger sample size, providing more statistical power and potentially improving the robustness of analysis or models.\n",
    "    \n",
    "    Filling missing values can enhance interpretability by providing a more comprehensive dataset for analysis and decision-making.\n",
    "    \n",
    "**How did i implement Filling Missing Values:**\n",
    "\n",
    "I introduce Data Imputation Techniques:\n",
    "\n",
    "By using Median to Impute For numerical variables, then mode for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefdf30",
   "metadata": {},
   "source": [
    "### task  19\n",
    "\n",
    "How and why did you decide to handle the duplicates?\n",
    "\n",
    "### Solution\n",
    "\n",
    "**Why I Handle Duplicates in the datasets is because:**\n",
    "    \n",
    "    Eliminating duplicates helps ensure data accuracy and integrity, preventing overrepresentation of certain observations.\n",
    "    \n",
    "    Duplicate entries can skew statistical analysis or machine learning models, leading to biased estimates or predictions.\n",
    "    \n",
    "    Large numbers of duplicates increase computational burden and processing time, especially in complex analyses.\n",
    "    \n",
    "    Many algorithms may give undue importance to duplicated instances, affecting model training and performance negatively.\n",
    "    \n",
    "    \n",
    " **How I Handle Duplicates in the dataset:**\n",
    " \n",
    "     Use decided to use functions base method to detect duplicate rows or observations within the dataset.\n",
    "     \n",
    "    Identify duplicate entries based on specific columns across the entire dataset.\n",
    "    \n",
    "    When implementing this method, i found out that there was no duplicate in the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ae655",
   "metadata": {},
   "source": [
    "### task  20\n",
    "\n",
    " How and why did you decide to apply a certain approach to handle extreme values?\n",
    "\n",
    "### Solution\n",
    "\n",
    "\n",
    "**Why Handle Extreme Values:**\n",
    "\n",
    "The main i decied to handle Extreme Values are:\n",
    "\n",
    "    Extreme values can adversely affect data integrity, leading to biased estimations or misleading analysis results.\n",
    "    \n",
    "    Outliers might obscure patterns or trends in the data. Addressing extreme values enhances interpretability by focusing on the underlying data distribution.\n",
    "    \n",
    "    Outliers can bias statistical estimates, such as means and variances, affecting the validity of conclusions drawn from the data.\n",
    "    \n",
    "    \n",
    " **How to Decide Handling Extreme Values:**\n",
    " \n",
    " I Ploted boxplots to visually identify observations that significantly deviate from the majority of the data.\n",
    "    \n",
    "![Image Description](outl.png)\n",
    "\n",
    "I use the Z-score to measures how many standard deviations a particular data point is from the mean of the dataset. \n",
    "\n",
    "Here's how the Z-score method works for outlier detection:\n",
    "\n",
    "For each data point in a numerical variable, compute its Z-score using the formula: Z=(X−μ)σZ=σ(X−μ)​\n",
    "\n",
    "Where XX is the data point, μμ is the mean of the variable, and σσ is the standard deviation.\n",
    "\n",
    " I then Determine a threshold value for Z-scores. Common thresholds are often around ±2.5±2.5 or ±3±3, indicating data points that are more than 2.5 or 3 standard deviations away from the mean.\n",
    " \n",
    " Any data point with a Z-score greater than or less than the chosen threshold is considered an outlier.\n",
    " \n",
    " after carrying out the processs, i realized that 139 rows are being detected as outliers.\n",
    " then i use the drop function to remove the identified outliers.\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec59f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eded6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1250868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11f71c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c4ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
